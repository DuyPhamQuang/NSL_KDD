{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "78b52670-4906-41cc-a4bd-24f09153e9e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import math\n",
    "import itertools\n",
    "import multiprocessing\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split \n",
    "from sklearn.model_selection import KFold\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import TensorDataset, DataLoader, Subset\n",
    "import seaborn as sns\n",
    "from time import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "2233b57c-b39c-4bc0-a99b-bc4df656ad12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of examples in train set: 125973\n",
      "Number of examples in test set: 22544\n"
     ]
    }
   ],
   "source": [
    "#Loading data\n",
    "train_data = pd.read_csv('NSL_KDD_Dataset/KDDTrain+.txt', header=None)\n",
    "test_data = pd.read_csv('NSL_KDD_Dataset/KDDTest+.txt', header=None)\n",
    "\n",
    "print(f\"Number of examples in train set: {train_data.shape[0]}\")\n",
    "print(f\"Number of examples in test set: {test_data.shape[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "c8e79970-4629-4b49-a080-38b271e52072",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Add labels\n",
    "columns = (['duration'\n",
    ",'protocol_type'\n",
    ",'service'\n",
    ",'flag'\n",
    ",'src_bytes'\n",
    ",'dst_bytes'\n",
    ",'land'\n",
    ",'wrong_fragment'\n",
    ",'urgent'\n",
    ",'hot'\n",
    ",'num_failed_logins'\n",
    ",'logged_in'\n",
    ",'num_compromised'\n",
    ",'root_shell'\n",
    ",'su_attempted'\n",
    ",'num_root'\n",
    ",'num_file_creations'\n",
    ",'num_shells'\n",
    ",'num_access_files'\n",
    ",'num_outbound_cmds'\n",
    ",'is_host_login'\n",
    ",'is_guest_login'\n",
    ",'count'\n",
    ",'srv_count'\n",
    ",'serror_rate'\n",
    ",'srv_serror_rate'\n",
    ",'rerror_rate'\n",
    ",'srv_rerror_rate'\n",
    ",'same_srv_rate'\n",
    ",'diff_srv_rate'\n",
    ",'srv_diff_host_rate'\n",
    ",'dst_host_count'\n",
    ",'dst_host_srv_count'\n",
    ",'dst_host_same_srv_rate'\n",
    ",'dst_host_diff_srv_rate'\n",
    ",'dst_host_same_src_port_rate'\n",
    ",'dst_host_srv_diff_host_rate'\n",
    ",'dst_host_serror_rate'\n",
    ",'dst_host_srv_serror_rate'\n",
    ",'dst_host_rerror_rate'\n",
    ",'dst_host_srv_rerror_rate'\n",
    ",'class'\n",
    ",'difficulty_level'])\n",
    "\n",
    "train_data.columns = columns\n",
    "test_data.columns = columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "7be51e98-0718-4829-9636-ca952b20c8d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set:\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>duration</th>\n",
       "      <th>protocol_type</th>\n",
       "      <th>service</th>\n",
       "      <th>flag</th>\n",
       "      <th>src_bytes</th>\n",
       "      <th>dst_bytes</th>\n",
       "      <th>land</th>\n",
       "      <th>wrong_fragment</th>\n",
       "      <th>urgent</th>\n",
       "      <th>hot</th>\n",
       "      <th>...</th>\n",
       "      <th>dst_host_same_srv_rate</th>\n",
       "      <th>dst_host_diff_srv_rate</th>\n",
       "      <th>dst_host_same_src_port_rate</th>\n",
       "      <th>dst_host_srv_diff_host_rate</th>\n",
       "      <th>dst_host_serror_rate</th>\n",
       "      <th>dst_host_srv_serror_rate</th>\n",
       "      <th>dst_host_rerror_rate</th>\n",
       "      <th>dst_host_srv_rerror_rate</th>\n",
       "      <th>class</th>\n",
       "      <th>difficulty_level</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>tcp</td>\n",
       "      <td>ftp_data</td>\n",
       "      <td>SF</td>\n",
       "      <td>491</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.00</td>\n",
       "      <td>normal</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>udp</td>\n",
       "      <td>other</td>\n",
       "      <td>SF</td>\n",
       "      <td>146</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.60</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>normal</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>tcp</td>\n",
       "      <td>private</td>\n",
       "      <td>S0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>neptune</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>tcp</td>\n",
       "      <td>http</td>\n",
       "      <td>SF</td>\n",
       "      <td>232</td>\n",
       "      <td>8153</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.01</td>\n",
       "      <td>normal</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>tcp</td>\n",
       "      <td>http</td>\n",
       "      <td>SF</td>\n",
       "      <td>199</td>\n",
       "      <td>420</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>normal</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 43 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   duration protocol_type   service flag  src_bytes  dst_bytes  land  \\\n",
       "0         0           tcp  ftp_data   SF        491          0     0   \n",
       "1         0           udp     other   SF        146          0     0   \n",
       "2         0           tcp   private   S0          0          0     0   \n",
       "3         0           tcp      http   SF        232       8153     0   \n",
       "4         0           tcp      http   SF        199        420     0   \n",
       "\n",
       "   wrong_fragment  urgent  hot  ...  dst_host_same_srv_rate  \\\n",
       "0               0       0    0  ...                    0.17   \n",
       "1               0       0    0  ...                    0.00   \n",
       "2               0       0    0  ...                    0.10   \n",
       "3               0       0    0  ...                    1.00   \n",
       "4               0       0    0  ...                    1.00   \n",
       "\n",
       "   dst_host_diff_srv_rate  dst_host_same_src_port_rate  \\\n",
       "0                    0.03                         0.17   \n",
       "1                    0.60                         0.88   \n",
       "2                    0.05                         0.00   \n",
       "3                    0.00                         0.03   \n",
       "4                    0.00                         0.00   \n",
       "\n",
       "   dst_host_srv_diff_host_rate  dst_host_serror_rate  \\\n",
       "0                         0.00                  0.00   \n",
       "1                         0.00                  0.00   \n",
       "2                         0.00                  1.00   \n",
       "3                         0.04                  0.03   \n",
       "4                         0.00                  0.00   \n",
       "\n",
       "   dst_host_srv_serror_rate  dst_host_rerror_rate  dst_host_srv_rerror_rate  \\\n",
       "0                      0.00                  0.05                      0.00   \n",
       "1                      0.00                  0.00                      0.00   \n",
       "2                      1.00                  0.00                      0.00   \n",
       "3                      0.01                  0.00                      0.01   \n",
       "4                      0.00                  0.00                      0.00   \n",
       "\n",
       "     class  difficulty_level  \n",
       "0   normal                20  \n",
       "1   normal                15  \n",
       "2  neptune                19  \n",
       "3   normal                21  \n",
       "4   normal                21  \n",
       "\n",
       "[5 rows x 43 columns]"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Sanity check\n",
    "print(f\"Training set:\\n\")\n",
    "train_data.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "1a95eed6-5ccc-4fe3-8bb0-64e388bf29a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set:\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>duration</th>\n",
       "      <th>protocol_type</th>\n",
       "      <th>service</th>\n",
       "      <th>flag</th>\n",
       "      <th>src_bytes</th>\n",
       "      <th>dst_bytes</th>\n",
       "      <th>land</th>\n",
       "      <th>wrong_fragment</th>\n",
       "      <th>urgent</th>\n",
       "      <th>hot</th>\n",
       "      <th>...</th>\n",
       "      <th>dst_host_same_srv_rate</th>\n",
       "      <th>dst_host_diff_srv_rate</th>\n",
       "      <th>dst_host_same_src_port_rate</th>\n",
       "      <th>dst_host_srv_diff_host_rate</th>\n",
       "      <th>dst_host_serror_rate</th>\n",
       "      <th>dst_host_srv_serror_rate</th>\n",
       "      <th>dst_host_rerror_rate</th>\n",
       "      <th>dst_host_srv_rerror_rate</th>\n",
       "      <th>class</th>\n",
       "      <th>difficulty_level</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>tcp</td>\n",
       "      <td>private</td>\n",
       "      <td>REJ</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>neptune</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>tcp</td>\n",
       "      <td>private</td>\n",
       "      <td>REJ</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>neptune</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>tcp</td>\n",
       "      <td>ftp_data</td>\n",
       "      <td>SF</td>\n",
       "      <td>12983</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.61</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.61</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>normal</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>icmp</td>\n",
       "      <td>eco_i</td>\n",
       "      <td>SF</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>saint</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>tcp</td>\n",
       "      <td>telnet</td>\n",
       "      <td>RSTO</td>\n",
       "      <td>0</td>\n",
       "      <td>15</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.83</td>\n",
       "      <td>0.71</td>\n",
       "      <td>mscan</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 43 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   duration protocol_type   service  flag  src_bytes  dst_bytes  land  \\\n",
       "0         0           tcp   private   REJ          0          0     0   \n",
       "1         0           tcp   private   REJ          0          0     0   \n",
       "2         2           tcp  ftp_data    SF      12983          0     0   \n",
       "3         0          icmp     eco_i    SF         20          0     0   \n",
       "4         1           tcp    telnet  RSTO          0         15     0   \n",
       "\n",
       "   wrong_fragment  urgent  hot  ...  dst_host_same_srv_rate  \\\n",
       "0               0       0    0  ...                    0.04   \n",
       "1               0       0    0  ...                    0.00   \n",
       "2               0       0    0  ...                    0.61   \n",
       "3               0       0    0  ...                    1.00   \n",
       "4               0       0    0  ...                    0.31   \n",
       "\n",
       "   dst_host_diff_srv_rate  dst_host_same_src_port_rate  \\\n",
       "0                    0.06                         0.00   \n",
       "1                    0.06                         0.00   \n",
       "2                    0.04                         0.61   \n",
       "3                    0.00                         1.00   \n",
       "4                    0.17                         0.03   \n",
       "\n",
       "   dst_host_srv_diff_host_rate  dst_host_serror_rate  \\\n",
       "0                         0.00                   0.0   \n",
       "1                         0.00                   0.0   \n",
       "2                         0.02                   0.0   \n",
       "3                         0.28                   0.0   \n",
       "4                         0.02                   0.0   \n",
       "\n",
       "   dst_host_srv_serror_rate  dst_host_rerror_rate  dst_host_srv_rerror_rate  \\\n",
       "0                       0.0                  1.00                      1.00   \n",
       "1                       0.0                  1.00                      1.00   \n",
       "2                       0.0                  0.00                      0.00   \n",
       "3                       0.0                  0.00                      0.00   \n",
       "4                       0.0                  0.83                      0.71   \n",
       "\n",
       "     class  difficulty_level  \n",
       "0  neptune                21  \n",
       "1  neptune                21  \n",
       "2   normal                21  \n",
       "3    saint                15  \n",
       "4    mscan                11  \n",
       "\n",
       "[5 rows x 43 columns]"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(f\"Test set:\\n\")\n",
    "test_data.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "74d3431f-f61e-4b68-9474-b5338c8a86b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>duration</th>\n",
       "      <td>22544.0</td>\n",
       "      <td>218.859076</td>\n",
       "      <td>1407.176612</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>57715.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>src_bytes</th>\n",
       "      <td>22544.0</td>\n",
       "      <td>10395.450231</td>\n",
       "      <td>472786.431088</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>54.00</td>\n",
       "      <td>287.0000</td>\n",
       "      <td>62825648.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dst_bytes</th>\n",
       "      <td>22544.0</td>\n",
       "      <td>2056.018808</td>\n",
       "      <td>21219.297609</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>46.00</td>\n",
       "      <td>601.0000</td>\n",
       "      <td>1345927.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>land</th>\n",
       "      <td>22544.0</td>\n",
       "      <td>0.000311</td>\n",
       "      <td>0.017619</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>wrong_fragment</th>\n",
       "      <td>22544.0</td>\n",
       "      <td>0.008428</td>\n",
       "      <td>0.142599</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>urgent</th>\n",
       "      <td>22544.0</td>\n",
       "      <td>0.000710</td>\n",
       "      <td>0.036473</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hot</th>\n",
       "      <td>22544.0</td>\n",
       "      <td>0.105394</td>\n",
       "      <td>0.928428</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>101.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>num_failed_logins</th>\n",
       "      <td>22544.0</td>\n",
       "      <td>0.021647</td>\n",
       "      <td>0.150328</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>logged_in</th>\n",
       "      <td>22544.0</td>\n",
       "      <td>0.442202</td>\n",
       "      <td>0.496659</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>num_compromised</th>\n",
       "      <td>22544.0</td>\n",
       "      <td>0.119899</td>\n",
       "      <td>7.269597</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>796.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>root_shell</th>\n",
       "      <td>22544.0</td>\n",
       "      <td>0.002440</td>\n",
       "      <td>0.049334</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>su_attempted</th>\n",
       "      <td>22544.0</td>\n",
       "      <td>0.000266</td>\n",
       "      <td>0.021060</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>num_root</th>\n",
       "      <td>22544.0</td>\n",
       "      <td>0.114665</td>\n",
       "      <td>8.041614</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>878.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>num_file_creations</th>\n",
       "      <td>22544.0</td>\n",
       "      <td>0.008738</td>\n",
       "      <td>0.676842</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>num_shells</th>\n",
       "      <td>22544.0</td>\n",
       "      <td>0.001153</td>\n",
       "      <td>0.048014</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>num_access_files</th>\n",
       "      <td>22544.0</td>\n",
       "      <td>0.003549</td>\n",
       "      <td>0.067829</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>num_outbound_cmds</th>\n",
       "      <td>22544.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>is_host_login</th>\n",
       "      <td>22544.0</td>\n",
       "      <td>0.000488</td>\n",
       "      <td>0.022084</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>is_guest_login</th>\n",
       "      <td>22544.0</td>\n",
       "      <td>0.028433</td>\n",
       "      <td>0.166211</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>22544.0</td>\n",
       "      <td>79.028345</td>\n",
       "      <td>128.539248</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>8.00</td>\n",
       "      <td>123.2500</td>\n",
       "      <td>511.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>srv_count</th>\n",
       "      <td>22544.0</td>\n",
       "      <td>31.124379</td>\n",
       "      <td>89.062532</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>6.00</td>\n",
       "      <td>16.0000</td>\n",
       "      <td>511.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>serror_rate</th>\n",
       "      <td>22544.0</td>\n",
       "      <td>0.102924</td>\n",
       "      <td>0.295367</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>srv_serror_rate</th>\n",
       "      <td>22544.0</td>\n",
       "      <td>0.103635</td>\n",
       "      <td>0.298332</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rerror_rate</th>\n",
       "      <td>22544.0</td>\n",
       "      <td>0.238463</td>\n",
       "      <td>0.416118</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.2500</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>srv_rerror_rate</th>\n",
       "      <td>22544.0</td>\n",
       "      <td>0.235179</td>\n",
       "      <td>0.416215</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0725</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>same_srv_rate</th>\n",
       "      <td>22544.0</td>\n",
       "      <td>0.740345</td>\n",
       "      <td>0.412496</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.25</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>diff_srv_rate</th>\n",
       "      <td>22544.0</td>\n",
       "      <td>0.094074</td>\n",
       "      <td>0.259138</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0600</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>srv_diff_host_rate</th>\n",
       "      <td>22544.0</td>\n",
       "      <td>0.098110</td>\n",
       "      <td>0.253545</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dst_host_count</th>\n",
       "      <td>22544.0</td>\n",
       "      <td>193.869411</td>\n",
       "      <td>94.035663</td>\n",
       "      <td>0.0</td>\n",
       "      <td>121.00</td>\n",
       "      <td>255.00</td>\n",
       "      <td>255.0000</td>\n",
       "      <td>255.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dst_host_srv_count</th>\n",
       "      <td>22544.0</td>\n",
       "      <td>140.750532</td>\n",
       "      <td>111.783972</td>\n",
       "      <td>0.0</td>\n",
       "      <td>15.00</td>\n",
       "      <td>168.00</td>\n",
       "      <td>255.0000</td>\n",
       "      <td>255.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dst_host_same_srv_rate</th>\n",
       "      <td>22544.0</td>\n",
       "      <td>0.608722</td>\n",
       "      <td>0.435688</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.92</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dst_host_diff_srv_rate</th>\n",
       "      <td>22544.0</td>\n",
       "      <td>0.090540</td>\n",
       "      <td>0.220717</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.0600</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dst_host_same_src_port_rate</th>\n",
       "      <td>22544.0</td>\n",
       "      <td>0.132261</td>\n",
       "      <td>0.306268</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0300</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dst_host_srv_diff_host_rate</th>\n",
       "      <td>22544.0</td>\n",
       "      <td>0.019638</td>\n",
       "      <td>0.085394</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0100</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dst_host_serror_rate</th>\n",
       "      <td>22544.0</td>\n",
       "      <td>0.097814</td>\n",
       "      <td>0.273139</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dst_host_srv_serror_rate</th>\n",
       "      <td>22544.0</td>\n",
       "      <td>0.099426</td>\n",
       "      <td>0.281866</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dst_host_rerror_rate</th>\n",
       "      <td>22544.0</td>\n",
       "      <td>0.233385</td>\n",
       "      <td>0.387229</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.3600</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dst_host_srv_rerror_rate</th>\n",
       "      <td>22544.0</td>\n",
       "      <td>0.226683</td>\n",
       "      <td>0.400875</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.1700</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>difficulty_level</th>\n",
       "      <td>22544.0</td>\n",
       "      <td>18.017965</td>\n",
       "      <td>4.270361</td>\n",
       "      <td>0.0</td>\n",
       "      <td>17.00</td>\n",
       "      <td>20.00</td>\n",
       "      <td>21.0000</td>\n",
       "      <td>21.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                               count          mean            std  min  \\\n",
       "duration                     22544.0    218.859076    1407.176612  0.0   \n",
       "src_bytes                    22544.0  10395.450231  472786.431088  0.0   \n",
       "dst_bytes                    22544.0   2056.018808   21219.297609  0.0   \n",
       "land                         22544.0      0.000311       0.017619  0.0   \n",
       "wrong_fragment               22544.0      0.008428       0.142599  0.0   \n",
       "urgent                       22544.0      0.000710       0.036473  0.0   \n",
       "hot                          22544.0      0.105394       0.928428  0.0   \n",
       "num_failed_logins            22544.0      0.021647       0.150328  0.0   \n",
       "logged_in                    22544.0      0.442202       0.496659  0.0   \n",
       "num_compromised              22544.0      0.119899       7.269597  0.0   \n",
       "root_shell                   22544.0      0.002440       0.049334  0.0   \n",
       "su_attempted                 22544.0      0.000266       0.021060  0.0   \n",
       "num_root                     22544.0      0.114665       8.041614  0.0   \n",
       "num_file_creations           22544.0      0.008738       0.676842  0.0   \n",
       "num_shells                   22544.0      0.001153       0.048014  0.0   \n",
       "num_access_files             22544.0      0.003549       0.067829  0.0   \n",
       "num_outbound_cmds            22544.0      0.000000       0.000000  0.0   \n",
       "is_host_login                22544.0      0.000488       0.022084  0.0   \n",
       "is_guest_login               22544.0      0.028433       0.166211  0.0   \n",
       "count                        22544.0     79.028345     128.539248  0.0   \n",
       "srv_count                    22544.0     31.124379      89.062532  0.0   \n",
       "serror_rate                  22544.0      0.102924       0.295367  0.0   \n",
       "srv_serror_rate              22544.0      0.103635       0.298332  0.0   \n",
       "rerror_rate                  22544.0      0.238463       0.416118  0.0   \n",
       "srv_rerror_rate              22544.0      0.235179       0.416215  0.0   \n",
       "same_srv_rate                22544.0      0.740345       0.412496  0.0   \n",
       "diff_srv_rate                22544.0      0.094074       0.259138  0.0   \n",
       "srv_diff_host_rate           22544.0      0.098110       0.253545  0.0   \n",
       "dst_host_count               22544.0    193.869411      94.035663  0.0   \n",
       "dst_host_srv_count           22544.0    140.750532     111.783972  0.0   \n",
       "dst_host_same_srv_rate       22544.0      0.608722       0.435688  0.0   \n",
       "dst_host_diff_srv_rate       22544.0      0.090540       0.220717  0.0   \n",
       "dst_host_same_src_port_rate  22544.0      0.132261       0.306268  0.0   \n",
       "dst_host_srv_diff_host_rate  22544.0      0.019638       0.085394  0.0   \n",
       "dst_host_serror_rate         22544.0      0.097814       0.273139  0.0   \n",
       "dst_host_srv_serror_rate     22544.0      0.099426       0.281866  0.0   \n",
       "dst_host_rerror_rate         22544.0      0.233385       0.387229  0.0   \n",
       "dst_host_srv_rerror_rate     22544.0      0.226683       0.400875  0.0   \n",
       "difficulty_level             22544.0     18.017965       4.270361  0.0   \n",
       "\n",
       "                                25%     50%       75%         max  \n",
       "duration                       0.00    0.00    0.0000     57715.0  \n",
       "src_bytes                      0.00   54.00  287.0000  62825648.0  \n",
       "dst_bytes                      0.00   46.00  601.0000   1345927.0  \n",
       "land                           0.00    0.00    0.0000         1.0  \n",
       "wrong_fragment                 0.00    0.00    0.0000         3.0  \n",
       "urgent                         0.00    0.00    0.0000         3.0  \n",
       "hot                            0.00    0.00    0.0000       101.0  \n",
       "num_failed_logins              0.00    0.00    0.0000         4.0  \n",
       "logged_in                      0.00    0.00    1.0000         1.0  \n",
       "num_compromised                0.00    0.00    0.0000       796.0  \n",
       "root_shell                     0.00    0.00    0.0000         1.0  \n",
       "su_attempted                   0.00    0.00    0.0000         2.0  \n",
       "num_root                       0.00    0.00    0.0000       878.0  \n",
       "num_file_creations             0.00    0.00    0.0000       100.0  \n",
       "num_shells                     0.00    0.00    0.0000         5.0  \n",
       "num_access_files               0.00    0.00    0.0000         4.0  \n",
       "num_outbound_cmds              0.00    0.00    0.0000         0.0  \n",
       "is_host_login                  0.00    0.00    0.0000         1.0  \n",
       "is_guest_login                 0.00    0.00    0.0000         1.0  \n",
       "count                          1.00    8.00  123.2500       511.0  \n",
       "srv_count                      1.00    6.00   16.0000       511.0  \n",
       "serror_rate                    0.00    0.00    0.0000         1.0  \n",
       "srv_serror_rate                0.00    0.00    0.0000         1.0  \n",
       "rerror_rate                    0.00    0.00    0.2500         1.0  \n",
       "srv_rerror_rate                0.00    0.00    0.0725         1.0  \n",
       "same_srv_rate                  0.25    1.00    1.0000         1.0  \n",
       "diff_srv_rate                  0.00    0.00    0.0600         1.0  \n",
       "srv_diff_host_rate             0.00    0.00    0.0000         1.0  \n",
       "dst_host_count               121.00  255.00  255.0000       255.0  \n",
       "dst_host_srv_count            15.00  168.00  255.0000       255.0  \n",
       "dst_host_same_srv_rate         0.07    0.92    1.0000         1.0  \n",
       "dst_host_diff_srv_rate         0.00    0.01    0.0600         1.0  \n",
       "dst_host_same_src_port_rate    0.00    0.00    0.0300         1.0  \n",
       "dst_host_srv_diff_host_rate    0.00    0.00    0.0100         1.0  \n",
       "dst_host_serror_rate           0.00    0.00    0.0000         1.0  \n",
       "dst_host_srv_serror_rate       0.00    0.00    0.0000         1.0  \n",
       "dst_host_rerror_rate           0.00    0.00    0.3600         1.0  \n",
       "dst_host_srv_rerror_rate       0.00    0.00    0.1700         1.0  \n",
       "difficulty_level              17.00   20.00   21.0000        21.0  "
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data.describe().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "da9e4e6f-c48a-4319-a304-be6b77b6bdaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Filter normal data for training\n",
    "normal_train_data = train_data[train_data[\"class\"] == 'normal']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "316f4da9-4154-499d-823a-7cf3d5c9c466",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>duration</th>\n",
       "      <td>67343.0</td>\n",
       "      <td>168.587396</td>\n",
       "      <td>1304.452127</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>40504.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>src_bytes</th>\n",
       "      <td>67343.0</td>\n",
       "      <td>13133.279331</td>\n",
       "      <td>418113.134246</td>\n",
       "      <td>0.0</td>\n",
       "      <td>129.00</td>\n",
       "      <td>233.00</td>\n",
       "      <td>324.00</td>\n",
       "      <td>89581520.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dst_bytes</th>\n",
       "      <td>67343.0</td>\n",
       "      <td>4329.685223</td>\n",
       "      <td>65462.817703</td>\n",
       "      <td>0.0</td>\n",
       "      <td>105.00</td>\n",
       "      <td>379.00</td>\n",
       "      <td>2056.00</td>\n",
       "      <td>7028652.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>land</th>\n",
       "      <td>67343.0</td>\n",
       "      <td>0.000104</td>\n",
       "      <td>0.010195</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>wrong_fragment</th>\n",
       "      <td>67343.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>urgent</th>\n",
       "      <td>67343.0</td>\n",
       "      <td>0.000148</td>\n",
       "      <td>0.017233</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hot</th>\n",
       "      <td>67343.0</td>\n",
       "      <td>0.230655</td>\n",
       "      <td>2.308336</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>77.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>num_failed_logins</th>\n",
       "      <td>67343.0</td>\n",
       "      <td>0.001381</td>\n",
       "      <td>0.049480</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>logged_in</th>\n",
       "      <td>67343.0</td>\n",
       "      <td>0.710646</td>\n",
       "      <td>0.453466</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>num_compromised</th>\n",
       "      <td>67343.0</td>\n",
       "      <td>0.507076</td>\n",
       "      <td>32.743321</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>7479.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>root_shell</th>\n",
       "      <td>67343.0</td>\n",
       "      <td>0.002034</td>\n",
       "      <td>0.045058</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>su_attempted</th>\n",
       "      <td>67343.0</td>\n",
       "      <td>0.002049</td>\n",
       "      <td>0.061622</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>num_root</th>\n",
       "      <td>67343.0</td>\n",
       "      <td>0.562924</td>\n",
       "      <td>33.368296</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>7468.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>num_file_creations</th>\n",
       "      <td>67343.0</td>\n",
       "      <td>0.022274</td>\n",
       "      <td>0.651399</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>43.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>num_shells</th>\n",
       "      <td>67343.0</td>\n",
       "      <td>0.000609</td>\n",
       "      <td>0.025843</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>num_access_files</th>\n",
       "      <td>67343.0</td>\n",
       "      <td>0.007499</td>\n",
       "      <td>0.135105</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>num_outbound_cmds</th>\n",
       "      <td>67343.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>is_host_login</th>\n",
       "      <td>67343.0</td>\n",
       "      <td>0.000015</td>\n",
       "      <td>0.003853</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>is_guest_login</th>\n",
       "      <td>67343.0</td>\n",
       "      <td>0.012963</td>\n",
       "      <td>0.113118</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>67343.0</td>\n",
       "      <td>22.517945</td>\n",
       "      <td>54.026086</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>4.00</td>\n",
       "      <td>14.00</td>\n",
       "      <td>511.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>srv_count</th>\n",
       "      <td>67343.0</td>\n",
       "      <td>27.685654</td>\n",
       "      <td>60.182334</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.00</td>\n",
       "      <td>5.00</td>\n",
       "      <td>18.00</td>\n",
       "      <td>511.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>serror_rate</th>\n",
       "      <td>67343.0</td>\n",
       "      <td>0.013441</td>\n",
       "      <td>0.094211</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>srv_serror_rate</th>\n",
       "      <td>67343.0</td>\n",
       "      <td>0.012083</td>\n",
       "      <td>0.086426</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rerror_rate</th>\n",
       "      <td>67343.0</td>\n",
       "      <td>0.044196</td>\n",
       "      <td>0.202975</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>srv_rerror_rate</th>\n",
       "      <td>67343.0</td>\n",
       "      <td>0.044629</td>\n",
       "      <td>0.202264</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>same_srv_rate</th>\n",
       "      <td>67343.0</td>\n",
       "      <td>0.969360</td>\n",
       "      <td>0.144371</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>diff_srv_rate</th>\n",
       "      <td>67343.0</td>\n",
       "      <td>0.028788</td>\n",
       "      <td>0.145622</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>srv_diff_host_rate</th>\n",
       "      <td>67343.0</td>\n",
       "      <td>0.126263</td>\n",
       "      <td>0.271621</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.11</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dst_host_count</th>\n",
       "      <td>67343.0</td>\n",
       "      <td>147.431923</td>\n",
       "      <td>101.785400</td>\n",
       "      <td>0.0</td>\n",
       "      <td>40.00</td>\n",
       "      <td>156.00</td>\n",
       "      <td>255.00</td>\n",
       "      <td>255.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dst_host_srv_count</th>\n",
       "      <td>67343.0</td>\n",
       "      <td>190.285761</td>\n",
       "      <td>92.608377</td>\n",
       "      <td>0.0</td>\n",
       "      <td>121.00</td>\n",
       "      <td>255.00</td>\n",
       "      <td>255.00</td>\n",
       "      <td>255.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dst_host_same_srv_rate</th>\n",
       "      <td>67343.0</td>\n",
       "      <td>0.811875</td>\n",
       "      <td>0.324091</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.75</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dst_host_diff_srv_rate</th>\n",
       "      <td>67343.0</td>\n",
       "      <td>0.040134</td>\n",
       "      <td>0.128529</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.02</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dst_host_same_src_port_rate</th>\n",
       "      <td>67343.0</td>\n",
       "      <td>0.121726</td>\n",
       "      <td>0.254382</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.08</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dst_host_srv_diff_host_rate</th>\n",
       "      <td>67343.0</td>\n",
       "      <td>0.025996</td>\n",
       "      <td>0.068807</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.03</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dst_host_serror_rate</th>\n",
       "      <td>67343.0</td>\n",
       "      <td>0.013930</td>\n",
       "      <td>0.092006</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dst_host_srv_serror_rate</th>\n",
       "      <td>67343.0</td>\n",
       "      <td>0.006116</td>\n",
       "      <td>0.056724</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dst_host_rerror_rate</th>\n",
       "      <td>67343.0</td>\n",
       "      <td>0.046589</td>\n",
       "      <td>0.195306</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dst_host_srv_rerror_rate</th>\n",
       "      <td>67343.0</td>\n",
       "      <td>0.044698</td>\n",
       "      <td>0.192188</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>difficulty_level</th>\n",
       "      <td>67343.0</td>\n",
       "      <td>20.315920</td>\n",
       "      <td>1.482986</td>\n",
       "      <td>1.0</td>\n",
       "      <td>20.00</td>\n",
       "      <td>21.00</td>\n",
       "      <td>21.00</td>\n",
       "      <td>21.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                               count          mean            std  min  \\\n",
       "duration                     67343.0    168.587396    1304.452127  0.0   \n",
       "src_bytes                    67343.0  13133.279331  418113.134246  0.0   \n",
       "dst_bytes                    67343.0   4329.685223   65462.817703  0.0   \n",
       "land                         67343.0      0.000104       0.010195  0.0   \n",
       "wrong_fragment               67343.0      0.000000       0.000000  0.0   \n",
       "urgent                       67343.0      0.000148       0.017233  0.0   \n",
       "hot                          67343.0      0.230655       2.308336  0.0   \n",
       "num_failed_logins            67343.0      0.001381       0.049480  0.0   \n",
       "logged_in                    67343.0      0.710646       0.453466  0.0   \n",
       "num_compromised              67343.0      0.507076      32.743321  0.0   \n",
       "root_shell                   67343.0      0.002034       0.045058  0.0   \n",
       "su_attempted                 67343.0      0.002049       0.061622  0.0   \n",
       "num_root                     67343.0      0.562924      33.368296  0.0   \n",
       "num_file_creations           67343.0      0.022274       0.651399  0.0   \n",
       "num_shells                   67343.0      0.000609       0.025843  0.0   \n",
       "num_access_files             67343.0      0.007499       0.135105  0.0   \n",
       "num_outbound_cmds            67343.0      0.000000       0.000000  0.0   \n",
       "is_host_login                67343.0      0.000015       0.003853  0.0   \n",
       "is_guest_login               67343.0      0.012963       0.113118  0.0   \n",
       "count                        67343.0     22.517945      54.026086  0.0   \n",
       "srv_count                    67343.0     27.685654      60.182334  0.0   \n",
       "serror_rate                  67343.0      0.013441       0.094211  0.0   \n",
       "srv_serror_rate              67343.0      0.012083       0.086426  0.0   \n",
       "rerror_rate                  67343.0      0.044196       0.202975  0.0   \n",
       "srv_rerror_rate              67343.0      0.044629       0.202264  0.0   \n",
       "same_srv_rate                67343.0      0.969360       0.144371  0.0   \n",
       "diff_srv_rate                67343.0      0.028788       0.145622  0.0   \n",
       "srv_diff_host_rate           67343.0      0.126263       0.271621  0.0   \n",
       "dst_host_count               67343.0    147.431923     101.785400  0.0   \n",
       "dst_host_srv_count           67343.0    190.285761      92.608377  0.0   \n",
       "dst_host_same_srv_rate       67343.0      0.811875       0.324091  0.0   \n",
       "dst_host_diff_srv_rate       67343.0      0.040134       0.128529  0.0   \n",
       "dst_host_same_src_port_rate  67343.0      0.121726       0.254382  0.0   \n",
       "dst_host_srv_diff_host_rate  67343.0      0.025996       0.068807  0.0   \n",
       "dst_host_serror_rate         67343.0      0.013930       0.092006  0.0   \n",
       "dst_host_srv_serror_rate     67343.0      0.006116       0.056724  0.0   \n",
       "dst_host_rerror_rate         67343.0      0.046589       0.195306  0.0   \n",
       "dst_host_srv_rerror_rate     67343.0      0.044698       0.192188  0.0   \n",
       "difficulty_level             67343.0     20.315920       1.482986  1.0   \n",
       "\n",
       "                                25%     50%      75%         max  \n",
       "duration                       0.00    0.00     0.00     40504.0  \n",
       "src_bytes                    129.00  233.00   324.00  89581520.0  \n",
       "dst_bytes                    105.00  379.00  2056.00   7028652.0  \n",
       "land                           0.00    0.00     0.00         1.0  \n",
       "wrong_fragment                 0.00    0.00     0.00         0.0  \n",
       "urgent                         0.00    0.00     0.00         3.0  \n",
       "hot                            0.00    0.00     0.00        77.0  \n",
       "num_failed_logins              0.00    0.00     0.00         4.0  \n",
       "logged_in                      0.00    1.00     1.00         1.0  \n",
       "num_compromised                0.00    0.00     0.00      7479.0  \n",
       "root_shell                     0.00    0.00     0.00         1.0  \n",
       "su_attempted                   0.00    0.00     0.00         2.0  \n",
       "num_root                       0.00    0.00     0.00      7468.0  \n",
       "num_file_creations             0.00    0.00     0.00        43.0  \n",
       "num_shells                     0.00    0.00     0.00         2.0  \n",
       "num_access_files               0.00    0.00     0.00         9.0  \n",
       "num_outbound_cmds              0.00    0.00     0.00         0.0  \n",
       "is_host_login                  0.00    0.00     0.00         1.0  \n",
       "is_guest_login                 0.00    0.00     0.00         1.0  \n",
       "count                          1.00    4.00    14.00       511.0  \n",
       "srv_count                      2.00    5.00    18.00       511.0  \n",
       "serror_rate                    0.00    0.00     0.00         1.0  \n",
       "srv_serror_rate                0.00    0.00     0.00         1.0  \n",
       "rerror_rate                    0.00    0.00     0.00         1.0  \n",
       "srv_rerror_rate                0.00    0.00     0.00         1.0  \n",
       "same_srv_rate                  1.00    1.00     1.00         1.0  \n",
       "diff_srv_rate                  0.00    0.00     0.00         1.0  \n",
       "srv_diff_host_rate             0.00    0.00     0.11         1.0  \n",
       "dst_host_count                40.00  156.00   255.00       255.0  \n",
       "dst_host_srv_count           121.00  255.00   255.00       255.0  \n",
       "dst_host_same_srv_rate         0.75    1.00     1.00         1.0  \n",
       "dst_host_diff_srv_rate         0.00    0.00     0.02         1.0  \n",
       "dst_host_same_src_port_rate    0.00    0.01     0.08         1.0  \n",
       "dst_host_srv_diff_host_rate    0.00    0.00     0.03         1.0  \n",
       "dst_host_serror_rate           0.00    0.00     0.00         1.0  \n",
       "dst_host_srv_serror_rate       0.00    0.00     0.00         1.0  \n",
       "dst_host_rerror_rate           0.00    0.00     0.00         1.0  \n",
       "dst_host_srv_rerror_rate       0.00    0.00     0.00         1.0  \n",
       "difficulty_level              20.00   21.00    21.00        21.0  "
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "normal_train_data.describe().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "e8a3338e-b3f2-4a88-b9bb-f2e56829daa5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "duration                       0\n",
       "protocol_type                  0\n",
       "service                        0\n",
       "flag                           0\n",
       "src_bytes                      0\n",
       "dst_bytes                      0\n",
       "land                           0\n",
       "wrong_fragment                 0\n",
       "urgent                         0\n",
       "hot                            0\n",
       "num_failed_logins              0\n",
       "logged_in                      0\n",
       "num_compromised                0\n",
       "root_shell                     0\n",
       "su_attempted                   0\n",
       "num_root                       0\n",
       "num_file_creations             0\n",
       "num_shells                     0\n",
       "num_access_files               0\n",
       "num_outbound_cmds              0\n",
       "is_host_login                  0\n",
       "is_guest_login                 0\n",
       "count                          0\n",
       "srv_count                      0\n",
       "serror_rate                    0\n",
       "srv_serror_rate                0\n",
       "rerror_rate                    0\n",
       "srv_rerror_rate                0\n",
       "same_srv_rate                  0\n",
       "diff_srv_rate                  0\n",
       "srv_diff_host_rate             0\n",
       "dst_host_count                 0\n",
       "dst_host_srv_count             0\n",
       "dst_host_same_srv_rate         0\n",
       "dst_host_diff_srv_rate         0\n",
       "dst_host_same_src_port_rate    0\n",
       "dst_host_srv_diff_host_rate    0\n",
       "dst_host_serror_rate           0\n",
       "dst_host_srv_serror_rate       0\n",
       "dst_host_rerror_rate           0\n",
       "dst_host_srv_rerror_rate       0\n",
       "class                          0\n",
       "difficulty_level               0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Check null values on train set\n",
    "normal_train_data.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "ebc1d943-bb23-4b64-a8c8-0435acd532b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.int64(0)"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Check duplicated values on train set\n",
    "normal_train_data.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "c784fa46-7cb5-4987-945a-e1b7544ed332",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Column: protocol_type\n",
      "\n",
      "Unique Values: (3): ['tcp' 'udp' 'icmp']\n",
      "\n",
      "Column: service\n",
      "\n",
      "Unique Values: (26): ['ftp_data' 'other' 'http' 'telnet' 'domain_u' 'private' 'smtp' 'urp_i'\n",
      " 'finger' 'ftp' 'ecr_i' 'ntp_u' 'eco_i' 'time' 'auth' 'shell' 'pop_3'\n",
      " 'IRC' 'red_i' 'domain' 'X11' 'urh_i' 'imap4' 'tim_i' 'ssh' 'tftp_u']\n",
      "\n",
      "Column: flag\n",
      "\n",
      "Unique Values: (10): ['SF' 'REJ' 'RSTO' 'S0' 'S1' 'RSTR' 'S3' 'S2' 'OTH' 'SH']\n",
      "\n",
      "Number of features after encoding: 122\n",
      "\n",
      "Name of encoded features: ['protocol_type_icmp' 'protocol_type_tcp' 'protocol_type_udp'\n",
      " 'service_IRC' 'service_X11' 'service_Z39_50' 'service_aol' 'service_auth'\n",
      " 'service_bgp' 'service_courier' 'service_csnet_ns' 'service_ctf'\n",
      " 'service_daytime' 'service_discard' 'service_domain' 'service_domain_u'\n",
      " 'service_echo' 'service_eco_i' 'service_ecr_i' 'service_efs'\n",
      " 'service_exec' 'service_finger' 'service_ftp' 'service_ftp_data'\n",
      " 'service_gopher' 'service_harvest' 'service_hostnames' 'service_http'\n",
      " 'service_http_2784' 'service_http_443' 'service_http_8001'\n",
      " 'service_imap4' 'service_iso_tsap' 'service_klogin' 'service_kshell'\n",
      " 'service_ldap' 'service_link' 'service_login' 'service_mtp'\n",
      " 'service_name' 'service_netbios_dgm' 'service_netbios_ns'\n",
      " 'service_netbios_ssn' 'service_netstat' 'service_nnsp' 'service_nntp'\n",
      " 'service_ntp_u' 'service_other' 'service_pm_dump' 'service_pop_2'\n",
      " 'service_pop_3' 'service_printer' 'service_private' 'service_red_i'\n",
      " 'service_remote_job' 'service_rje' 'service_shell' 'service_smtp'\n",
      " 'service_sql_net' 'service_ssh' 'service_sunrpc' 'service_supdup'\n",
      " 'service_systat' 'service_telnet' 'service_tftp_u' 'service_tim_i'\n",
      " 'service_time' 'service_urh_i' 'service_urp_i' 'service_uucp'\n",
      " 'service_uucp_path' 'service_vmnet' 'service_whois' 'flag_OTH' 'flag_REJ'\n",
      " 'flag_RSTO' 'flag_RSTOS0' 'flag_RSTR' 'flag_S0' 'flag_S1' 'flag_S2'\n",
      " 'flag_S3' 'flag_SF' 'flag_SH']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "'''Handle Categorical Features'''\n",
    "\n",
    "# Filter out columns with type object\n",
    "categorical_cols = normal_train_data.select_dtypes(include=['object']).columns\n",
    "categorical_cols = [col for col in categorical_cols if col != 'class']  #Exclude class column\n",
    "\n",
    "#Determine unique values in NORMAL_TRAIN data\n",
    "for column_name in categorical_cols:\n",
    "    print(f\"Column: {column_name}\\n\")\n",
    "    unique_vals = normal_train_data[column_name].unique()\n",
    "    print(f\"Unique Values: ({len(unique_vals)}): {unique_vals}\\n\") \n",
    "\n",
    "## One-hot-Encoding\n",
    "# Initialize and fit OneHotEncoder\n",
    "encoder = OneHotEncoder(sparse_output=False, handle_unknown='ignore')\n",
    "encoder.fit(train_data[categorical_cols])\n",
    "\n",
    "# Transform categorical columns\n",
    "encoded_data = encoder.transform(normal_train_data[categorical_cols])\n",
    "encoded_feature_names = encoder.get_feature_names_out(categorical_cols)\n",
    "encoded_df = pd.DataFrame(encoded_data, columns=encoded_feature_names, index=normal_train_data.index)\n",
    "\n",
    "# Combine with numeric features excluding the difficulty level\n",
    "numeric_cols = [col for col in normal_train_data.columns if col not in categorical_cols and col != 'class' \n",
    "                and col != 'difficulty_level']\n",
    "normal_train_encoded = pd.concat([normal_train_data[numeric_cols], encoded_df], axis=1)\n",
    "print(f\"Number of features after encoding: {normal_train_encoded.shape[1]}\\n\")\n",
    "print(f\"Name of encoded features: {encoded_feature_names}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "055bf555-6b6d-42ff-b24f-507bad0d3dbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Normalize Numeric Features'''\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "numeric_cols = normal_train_encoded.select_dtypes(include=['int64', 'float64']).columns\n",
    "normal_train_encoded[numeric_cols] = scaler.fit_transform(normal_train_encoded[numeric_cols])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "d60ef2b8-8964-4338-a076-0955ce9801a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AutoEncoder(nn.Module):\n",
    "    '''\n",
    "    Design the AutoEncoder Architecture\n",
    "\n",
    "    Encoder: Compress input data into lower-dimensional representation \n",
    "      Input Layer: 122 neurons (number of features after encoding)\n",
    "      Hidden Layer 1: 64 neurons\n",
    "      Hidden Layer 2: 32 neurons\n",
    "\n",
    "    Bottleneck Layer: 16 neurons\n",
    "\n",
    "    Decoder: Reconstruct the data\n",
    "      Hidden Layer 3: 32 neurons\n",
    "      Hidden Layer 4: 64 neurons\n",
    "      Output Layer: 122 neurons (back to original dimension)\n",
    "\n",
    "    '''\n",
    "    def __init__(self):\n",
    "        super(AutoEncoder, self).__init__()\n",
    "\n",
    "        # Encoder\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Linear(122, 64),   # 122 -> 64 neurons\n",
    "            nn.ReLU(),   # ReLU activation\n",
    "            nn.Linear(64,32),   # 64 -> 32 neurons\n",
    "            nn.ReLU(),   # ReLU activation\n",
    "            nn.Linear(32, 16),   # 32 -> 16 neurons\n",
    "            nn.ReLU()   # ReLU activation\n",
    "        )\n",
    "\n",
    "        # Decoder\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Linear(16, 32),   # 16 -> 32 neurons\n",
    "            nn.ReLU(),   # RelU activation\n",
    "            nn.Linear(32, 64),   # 32 -> 64 neurons\n",
    "            nn.ReLU(),   # ReLU activation\n",
    "            nn.Linear(64, 122),   # 64 -> 122 neurons\n",
    "            nn.Sigmoid()   # Sigmoid activation\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        encoded = self.encoder(x)\n",
    "        decoded = self.decoder(encoded)\n",
    "        return decoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "d71b80f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#train_set, val_set = train_test_split(normal_train_encoded, test_size=0.2, random_state=42)\n",
    "#train_set = pd.DataFrame(train_set, columns=normal_train_encoded.columns)\n",
    "#train_set = np.vstack(train_set.values).astype(np.float32)\n",
    "#train_tensor = torch.tensor(train_set, dtype=torch.float32)\n",
    "#train_tensor.type(), train_tensor.shape, train_tensor.dtype\n",
    "\n",
    "\n",
    "#normal_train_encoded_tensor = torch.tensor(normal_train_encoded.values, dtype=torch.float32)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "6f283767",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training Fold 1/5\n",
      "Epoch 1/100, Train Loss: 0.01180865, Val Loss: 0.00310327\n",
      "Best model for fold 1 with train loss: 0.01180865 and val loss: 0.00310327\n",
      "Epoch 2/100, Train Loss: 0.00263071, Val Loss: 0.00227780\n",
      "Best model for fold 1 with train loss: 0.00263071 and val loss: 0.00227780\n",
      "Epoch 3/100, Train Loss: 0.00211583, Val Loss: 0.00201924\n",
      "Best model for fold 1 with train loss: 0.00211583 and val loss: 0.00201924\n",
      "Epoch 4/100, Train Loss: 0.00185899, Val Loss: 0.00167450\n",
      "Best model for fold 1 with train loss: 0.00185899 and val loss: 0.00167450\n",
      "Epoch 5/100, Train Loss: 0.00142567, Val Loss: 0.00125188\n",
      "Best model for fold 1 with train loss: 0.00142567 and val loss: 0.00125188\n",
      "Epoch 6/100, Train Loss: 0.00120965, Val Loss: 0.00117411\n",
      "Best model for fold 1 with train loss: 0.00120965 and val loss: 0.00117411\n",
      "Epoch 7/100, Train Loss: 0.00099068, Val Loss: 0.00092976\n",
      "Best model for fold 1 with train loss: 0.00099068 and val loss: 0.00092976\n",
      "Epoch 8/100, Train Loss: 0.00089578, Val Loss: 0.00086706\n",
      "Best model for fold 1 with train loss: 0.00089578 and val loss: 0.00086706\n",
      "Epoch 9/100, Train Loss: 0.00084113, Val Loss: 0.00079243\n",
      "Best model for fold 1 with train loss: 0.00084113 and val loss: 0.00079243\n",
      "Epoch 10/100, Train Loss: 0.00071107, Val Loss: 0.00074784\n",
      "Best model for fold 1 with train loss: 0.00071107 and val loss: 0.00074784\n",
      "Epoch 11/100, Train Loss: 0.00067586, Val Loss: 0.00074227\n",
      "Best model for fold 1 with train loss: 0.00067586 and val loss: 0.00074227\n",
      "Epoch 12/100, Train Loss: 0.00065059, Val Loss: 0.00064301\n",
      "Best model for fold 1 with train loss: 0.00065059 and val loss: 0.00064301\n",
      "Epoch 13/100, Train Loss: 0.00060385, Val Loss: 0.00061143\n",
      "Best model for fold 1 with train loss: 0.00060385 and val loss: 0.00061143\n",
      "Epoch 14/100, Train Loss: 0.00058316, Val Loss: 0.00062327\n",
      "Epoch 15/100, Train Loss: 0.00057148, Val Loss: 0.00057563\n",
      "Best model for fold 1 with train loss: 0.00057148 and val loss: 0.00057563\n",
      "Epoch 16/100, Train Loss: 0.00054981, Val Loss: 0.00055726\n",
      "Best model for fold 1 with train loss: 0.00054981 and val loss: 0.00055726\n",
      "Epoch 17/100, Train Loss: 0.00053603, Val Loss: 0.00055940\n",
      "Epoch 18/100, Train Loss: 0.00053353, Val Loss: 0.00054161\n",
      "Best model for fold 1 with train loss: 0.00053353 and val loss: 0.00054161\n",
      "Epoch 19/100, Train Loss: 0.00051948, Val Loss: 0.00050080\n",
      "Best model for fold 1 with train loss: 0.00051948 and val loss: 0.00050080\n",
      "Epoch 20/100, Train Loss: 0.00048527, Val Loss: 0.00049449\n",
      "Best model for fold 1 with train loss: 0.00048527 and val loss: 0.00049449\n",
      "Epoch 21/100, Train Loss: 0.00047482, Val Loss: 0.00046738\n",
      "Best model for fold 1 with train loss: 0.00047482 and val loss: 0.00046738\n",
      "Epoch 22/100, Train Loss: 0.00046478, Val Loss: 0.00043268\n",
      "Best model for fold 1 with train loss: 0.00046478 and val loss: 0.00043268\n",
      "Epoch 23/100, Train Loss: 0.00041578, Val Loss: 0.00043246\n",
      "Best model for fold 1 with train loss: 0.00041578 and val loss: 0.00043246\n",
      "Epoch 24/100, Train Loss: 0.00040349, Val Loss: 0.00043534\n",
      "Epoch 25/100, Train Loss: 0.00039596, Val Loss: 0.00040336\n",
      "Best model for fold 1 with train loss: 0.00039596 and val loss: 0.00040336\n",
      "Epoch 26/100, Train Loss: 0.00038622, Val Loss: 0.00040078\n",
      "Best model for fold 1 with train loss: 0.00038622 and val loss: 0.00040078\n",
      "Epoch 27/100, Train Loss: 0.00038067, Val Loss: 0.00041597\n",
      "Epoch 28/100, Train Loss: 0.00037346, Val Loss: 0.00038619\n",
      "Best model for fold 1 with train loss: 0.00037346 and val loss: 0.00038619\n",
      "Epoch 29/100, Train Loss: 0.00036566, Val Loss: 0.00038896\n",
      "Epoch 30/100, Train Loss: 0.00036588, Val Loss: 0.00037352\n",
      "Best model for fold 1 with train loss: 0.00036588 and val loss: 0.00037352\n",
      "Epoch 31/100, Train Loss: 0.00034711, Val Loss: 0.00035090\n",
      "Best model for fold 1 with train loss: 0.00034711 and val loss: 0.00035090\n",
      "Epoch 32/100, Train Loss: 0.00034147, Val Loss: 0.00034050\n",
      "Best model for fold 1 with train loss: 0.00034147 and val loss: 0.00034050\n",
      "Epoch 33/100, Train Loss: 0.00033672, Val Loss: 0.00036996\n",
      "Epoch 34/100, Train Loss: 0.00033034, Val Loss: 0.00034557\n",
      "Epoch 35/100, Train Loss: 0.00032690, Val Loss: 0.00035145\n",
      "Epoch 36/100, Train Loss: 0.00031842, Val Loss: 0.00035044\n",
      "Epoch 37/100, Train Loss: 0.00031539, Val Loss: 0.00034018\n",
      "Best model for fold 1 with train loss: 0.00031539 and val loss: 0.00034018\n",
      "Epoch 38/100, Train Loss: 0.00030613, Val Loss: 0.00033567\n",
      "Best model for fold 1 with train loss: 0.00030613 and val loss: 0.00033567\n",
      "Epoch 39/100, Train Loss: 0.00031298, Val Loss: 0.00032472\n",
      "Best model for fold 1 with train loss: 0.00031298 and val loss: 0.00032472\n",
      "Epoch 40/100, Train Loss: 0.00030438, Val Loss: 0.00031900\n",
      "Best model for fold 1 with train loss: 0.00030438 and val loss: 0.00031900\n",
      "Epoch 41/100, Train Loss: 0.00030021, Val Loss: 0.00034272\n",
      "Epoch 42/100, Train Loss: 0.00030010, Val Loss: 0.00032337\n",
      "Epoch 43/100, Train Loss: 0.00029541, Val Loss: 0.00032380\n",
      "Epoch 44/100, Train Loss: 0.00029218, Val Loss: 0.00031142\n",
      "Best model for fold 1 with train loss: 0.00029218 and val loss: 0.00031142\n",
      "Epoch 45/100, Train Loss: 0.00029210, Val Loss: 0.00031467\n",
      "Epoch 46/100, Train Loss: 0.00027813, Val Loss: 0.00030375\n",
      "Best model for fold 1 with train loss: 0.00027813 and val loss: 0.00030375\n",
      "Epoch 47/100, Train Loss: 0.00028258, Val Loss: 0.00034788\n",
      "Epoch 48/100, Train Loss: 0.00027723, Val Loss: 0.00030101\n",
      "Best model for fold 1 with train loss: 0.00027723 and val loss: 0.00030101\n",
      "Epoch 49/100, Train Loss: 0.00027721, Val Loss: 0.00029944\n",
      "Best model for fold 1 with train loss: 0.00027721 and val loss: 0.00029944\n",
      "Epoch 50/100, Train Loss: 0.00027164, Val Loss: 0.00029288\n",
      "Best model for fold 1 with train loss: 0.00027164 and val loss: 0.00029288\n",
      "Epoch 51/100, Train Loss: 0.00027965, Val Loss: 0.00029238\n",
      "Best model for fold 1 with train loss: 0.00027965 and val loss: 0.00029238\n",
      "Epoch 52/100, Train Loss: 0.00027020, Val Loss: 0.00029259\n",
      "Epoch 53/100, Train Loss: 0.00027529, Val Loss: 0.00030395\n",
      "Epoch 54/100, Train Loss: 0.00027289, Val Loss: 0.00029283\n",
      "Epoch 55/100, Train Loss: 0.00026900, Val Loss: 0.00027885\n",
      "Best model for fold 1 with train loss: 0.00026900 and val loss: 0.00027885\n",
      "Epoch 56/100, Train Loss: 0.00026424, Val Loss: 0.00027907\n",
      "Epoch 57/100, Train Loss: 0.00026987, Val Loss: 0.00030066\n",
      "Epoch 58/100, Train Loss: 0.00026185, Val Loss: 0.00028040\n",
      "Epoch 59/100, Train Loss: 0.00027154, Val Loss: 0.00028083\n",
      "Epoch 60/100, Train Loss: 0.00026308, Val Loss: 0.00030711\n",
      "Early stopping at epoch 60 for fold 1\n",
      "\n",
      "Training Fold 2/5\n",
      "Epoch 1/100, Train Loss: 0.01475034, Val Loss: 0.00491229\n",
      "Best model for fold 2 with train loss: 0.01475034 and val loss: 0.00491229\n",
      "Epoch 2/100, Train Loss: 0.00368632, Val Loss: 0.00294575\n",
      "Best model for fold 2 with train loss: 0.00368632 and val loss: 0.00294575\n",
      "Epoch 3/100, Train Loss: 0.00266440, Val Loss: 0.00247737\n",
      "Best model for fold 2 with train loss: 0.00266440 and val loss: 0.00247737\n",
      "Epoch 4/100, Train Loss: 0.00210460, Val Loss: 0.00180278\n",
      "Best model for fold 2 with train loss: 0.00210460 and val loss: 0.00180278\n",
      "Epoch 5/100, Train Loss: 0.00165003, Val Loss: 0.00159569\n",
      "Best model for fold 2 with train loss: 0.00165003 and val loss: 0.00159569\n",
      "Epoch 6/100, Train Loss: 0.00145671, Val Loss: 0.00140805\n",
      "Best model for fold 2 with train loss: 0.00145671 and val loss: 0.00140805\n",
      "Epoch 7/100, Train Loss: 0.00136296, Val Loss: 0.00133909\n",
      "Best model for fold 2 with train loss: 0.00136296 and val loss: 0.00133909\n",
      "Epoch 8/100, Train Loss: 0.00113180, Val Loss: 0.00109714\n",
      "Best model for fold 2 with train loss: 0.00113180 and val loss: 0.00109714\n",
      "Epoch 9/100, Train Loss: 0.00102040, Val Loss: 0.00100944\n",
      "Best model for fold 2 with train loss: 0.00102040 and val loss: 0.00100944\n",
      "Epoch 10/100, Train Loss: 0.00092792, Val Loss: 0.00094087\n",
      "Best model for fold 2 with train loss: 0.00092792 and val loss: 0.00094087\n",
      "Epoch 11/100, Train Loss: 0.00088138, Val Loss: 0.00086148\n",
      "Best model for fold 2 with train loss: 0.00088138 and val loss: 0.00086148\n",
      "Epoch 12/100, Train Loss: 0.00077913, Val Loss: 0.00076878\n",
      "Best model for fold 2 with train loss: 0.00077913 and val loss: 0.00076878\n",
      "Epoch 13/100, Train Loss: 0.00069170, Val Loss: 0.00069174\n",
      "Best model for fold 2 with train loss: 0.00069170 and val loss: 0.00069174\n",
      "Epoch 14/100, Train Loss: 0.00064674, Val Loss: 0.00066533\n",
      "Best model for fold 2 with train loss: 0.00064674 and val loss: 0.00066533\n",
      "Epoch 15/100, Train Loss: 0.00059000, Val Loss: 0.00059808\n",
      "Best model for fold 2 with train loss: 0.00059000 and val loss: 0.00059808\n",
      "Epoch 16/100, Train Loss: 0.00056096, Val Loss: 0.00061774\n",
      "Epoch 17/100, Train Loss: 0.00053991, Val Loss: 0.00058451\n",
      "Best model for fold 2 with train loss: 0.00053991 and val loss: 0.00058451\n",
      "Epoch 18/100, Train Loss: 0.00052539, Val Loss: 0.00054701\n",
      "Best model for fold 2 with train loss: 0.00052539 and val loss: 0.00054701\n",
      "Epoch 19/100, Train Loss: 0.00050278, Val Loss: 0.00052835\n",
      "Best model for fold 2 with train loss: 0.00050278 and val loss: 0.00052835\n",
      "Epoch 20/100, Train Loss: 0.00048957, Val Loss: 0.00051685\n",
      "Best model for fold 2 with train loss: 0.00048957 and val loss: 0.00051685\n",
      "Epoch 21/100, Train Loss: 0.00048379, Val Loss: 0.00050404\n",
      "Best model for fold 2 with train loss: 0.00048379 and val loss: 0.00050404\n",
      "Epoch 22/100, Train Loss: 0.00047289, Val Loss: 0.00049334\n",
      "Best model for fold 2 with train loss: 0.00047289 and val loss: 0.00049334\n",
      "Epoch 23/100, Train Loss: 0.00046882, Val Loss: 0.00051863\n",
      "Epoch 24/100, Train Loss: 0.00045996, Val Loss: 0.00048503\n",
      "Best model for fold 2 with train loss: 0.00045996 and val loss: 0.00048503\n",
      "Epoch 25/100, Train Loss: 0.00045331, Val Loss: 0.00049856\n",
      "Epoch 26/100, Train Loss: 0.00044924, Val Loss: 0.00052009\n",
      "Epoch 27/100, Train Loss: 0.00043373, Val Loss: 0.00047122\n",
      "Best model for fold 2 with train loss: 0.00043373 and val loss: 0.00047122\n",
      "Epoch 28/100, Train Loss: 0.00042719, Val Loss: 0.00044664\n",
      "Best model for fold 2 with train loss: 0.00042719 and val loss: 0.00044664\n",
      "Epoch 29/100, Train Loss: 0.00039830, Val Loss: 0.00043314\n",
      "Best model for fold 2 with train loss: 0.00039830 and val loss: 0.00043314\n",
      "Epoch 30/100, Train Loss: 0.00039383, Val Loss: 0.00042654\n",
      "Best model for fold 2 with train loss: 0.00039383 and val loss: 0.00042654\n",
      "Epoch 31/100, Train Loss: 0.00038548, Val Loss: 0.00059638\n",
      "Epoch 32/100, Train Loss: 0.00038534, Val Loss: 0.00040810\n",
      "Best model for fold 2 with train loss: 0.00038534 and val loss: 0.00040810\n",
      "Epoch 33/100, Train Loss: 0.00037053, Val Loss: 0.00041981\n",
      "Epoch 34/100, Train Loss: 0.00035784, Val Loss: 0.00037489\n",
      "Best model for fold 2 with train loss: 0.00035784 and val loss: 0.00037489\n",
      "Epoch 35/100, Train Loss: 0.00034863, Val Loss: 0.00037678\n",
      "Epoch 36/100, Train Loss: 0.00034849, Val Loss: 0.00036458\n",
      "Best model for fold 2 with train loss: 0.00034849 and val loss: 0.00036458\n",
      "Epoch 37/100, Train Loss: 0.00034013, Val Loss: 0.00038973\n",
      "Epoch 38/100, Train Loss: 0.00033214, Val Loss: 0.00040260\n",
      "Epoch 39/100, Train Loss: 0.00033067, Val Loss: 0.00036127\n",
      "Best model for fold 2 with train loss: 0.00033067 and val loss: 0.00036127\n",
      "Epoch 40/100, Train Loss: 0.00031782, Val Loss: 0.00031815\n",
      "Best model for fold 2 with train loss: 0.00031782 and val loss: 0.00031815\n",
      "Epoch 41/100, Train Loss: 0.00027611, Val Loss: 0.00029331\n",
      "Best model for fold 2 with train loss: 0.00027611 and val loss: 0.00029331\n",
      "Epoch 42/100, Train Loss: 0.00026303, Val Loss: 0.00027671\n",
      "Best model for fold 2 with train loss: 0.00026303 and val loss: 0.00027671\n",
      "Epoch 43/100, Train Loss: 0.00025406, Val Loss: 0.00029464\n",
      "Epoch 44/100, Train Loss: 0.00025000, Val Loss: 0.00027474\n",
      "Best model for fold 2 with train loss: 0.00025000 and val loss: 0.00027474\n",
      "Epoch 45/100, Train Loss: 0.00024111, Val Loss: 0.00029225\n",
      "Epoch 46/100, Train Loss: 0.00024906, Val Loss: 0.00032057\n",
      "Epoch 47/100, Train Loss: 0.00024380, Val Loss: 0.00026483\n",
      "Best model for fold 2 with train loss: 0.00024380 and val loss: 0.00026483\n",
      "Epoch 48/100, Train Loss: 0.00023587, Val Loss: 0.00025491\n",
      "Best model for fold 2 with train loss: 0.00023587 and val loss: 0.00025491\n",
      "Epoch 49/100, Train Loss: 0.00024025, Val Loss: 0.00029203\n",
      "Epoch 50/100, Train Loss: 0.00023575, Val Loss: 0.00025211\n",
      "Best model for fold 2 with train loss: 0.00023575 and val loss: 0.00025211\n",
      "Epoch 51/100, Train Loss: 0.00023783, Val Loss: 0.00026119\n",
      "Epoch 52/100, Train Loss: 0.00023467, Val Loss: 0.00025742\n",
      "Epoch 53/100, Train Loss: 0.00023347, Val Loss: 0.00025758\n",
      "Epoch 54/100, Train Loss: 0.00022620, Val Loss: 0.00024985\n",
      "Best model for fold 2 with train loss: 0.00022620 and val loss: 0.00024985\n",
      "Epoch 55/100, Train Loss: 0.00022766, Val Loss: 0.00025678\n",
      "Epoch 56/100, Train Loss: 0.00022811, Val Loss: 0.00028590\n",
      "Epoch 57/100, Train Loss: 0.00022087, Val Loss: 0.00024686\n",
      "Best model for fold 2 with train loss: 0.00022087 and val loss: 0.00024686\n",
      "Epoch 58/100, Train Loss: 0.00022022, Val Loss: 0.00031251\n",
      "Epoch 59/100, Train Loss: 0.00022429, Val Loss: 0.00027425\n",
      "Epoch 60/100, Train Loss: 0.00021799, Val Loss: 0.00024054\n",
      "Best model for fold 2 with train loss: 0.00021799 and val loss: 0.00024054\n",
      "Epoch 61/100, Train Loss: 0.00022732, Val Loss: 0.00023471\n",
      "Best model for fold 2 with train loss: 0.00022732 and val loss: 0.00023471\n",
      "Epoch 62/100, Train Loss: 0.00022023, Val Loss: 0.00024228\n",
      "Epoch 63/100, Train Loss: 0.00021523, Val Loss: 0.00023625\n",
      "Epoch 64/100, Train Loss: 0.00021536, Val Loss: 0.00028483\n",
      "Epoch 65/100, Train Loss: 0.00021974, Val Loss: 0.00023680\n",
      "Epoch 66/100, Train Loss: 0.00021787, Val Loss: 0.00023790\n",
      "Early stopping at epoch 66 for fold 2\n",
      "\n",
      "Training Fold 3/5\n",
      "Epoch 1/100, Train Loss: 0.01180260, Val Loss: 0.00304925\n",
      "Best model for fold 3 with train loss: 0.01180260 and val loss: 0.00304925\n",
      "Epoch 2/100, Train Loss: 0.00226710, Val Loss: 0.00196179\n",
      "Best model for fold 3 with train loss: 0.00226710 and val loss: 0.00196179\n",
      "Epoch 3/100, Train Loss: 0.00176659, Val Loss: 0.00168490\n",
      "Best model for fold 3 with train loss: 0.00176659 and val loss: 0.00168490\n",
      "Epoch 4/100, Train Loss: 0.00157715, Val Loss: 0.00158381\n",
      "Best model for fold 3 with train loss: 0.00157715 and val loss: 0.00158381\n",
      "Epoch 5/100, Train Loss: 0.00148837, Val Loss: 0.00150760\n",
      "Best model for fold 3 with train loss: 0.00148837 and val loss: 0.00150760\n",
      "Epoch 6/100, Train Loss: 0.00137269, Val Loss: 0.00136729\n",
      "Best model for fold 3 with train loss: 0.00137269 and val loss: 0.00136729\n",
      "Epoch 7/100, Train Loss: 0.00125706, Val Loss: 0.00122937\n",
      "Best model for fold 3 with train loss: 0.00125706 and val loss: 0.00122937\n",
      "Epoch 8/100, Train Loss: 0.00111941, Val Loss: 0.00101829\n",
      "Best model for fold 3 with train loss: 0.00111941 and val loss: 0.00101829\n",
      "Epoch 9/100, Train Loss: 0.00097105, Val Loss: 0.00098391\n",
      "Best model for fold 3 with train loss: 0.00097105 and val loss: 0.00098391\n",
      "Epoch 10/100, Train Loss: 0.00091514, Val Loss: 0.00096195\n",
      "Best model for fold 3 with train loss: 0.00091514 and val loss: 0.00096195\n",
      "Epoch 11/100, Train Loss: 0.00086613, Val Loss: 0.00087945\n",
      "Best model for fold 3 with train loss: 0.00086613 and val loss: 0.00087945\n",
      "Epoch 12/100, Train Loss: 0.00082843, Val Loss: 0.00085593\n",
      "Best model for fold 3 with train loss: 0.00082843 and val loss: 0.00085593\n",
      "Epoch 13/100, Train Loss: 0.00081221, Val Loss: 0.00083812\n",
      "Best model for fold 3 with train loss: 0.00081221 and val loss: 0.00083812\n",
      "Epoch 14/100, Train Loss: 0.00076415, Val Loss: 0.00079013\n",
      "Best model for fold 3 with train loss: 0.00076415 and val loss: 0.00079013\n",
      "Epoch 15/100, Train Loss: 0.00074871, Val Loss: 0.00078292\n",
      "Best model for fold 3 with train loss: 0.00074871 and val loss: 0.00078292\n",
      "Epoch 16/100, Train Loss: 0.00072971, Val Loss: 0.00086316\n",
      "Epoch 17/100, Train Loss: 0.00072717, Val Loss: 0.00075980\n",
      "Best model for fold 3 with train loss: 0.00072717 and val loss: 0.00075980\n",
      "Epoch 18/100, Train Loss: 0.00072176, Val Loss: 0.00073590\n",
      "Best model for fold 3 with train loss: 0.00072176 and val loss: 0.00073590\n",
      "Epoch 19/100, Train Loss: 0.00071082, Val Loss: 0.00072852\n",
      "Best model for fold 3 with train loss: 0.00071082 and val loss: 0.00072852\n",
      "Epoch 20/100, Train Loss: 0.00070563, Val Loss: 0.00075702\n",
      "Epoch 21/100, Train Loss: 0.00070386, Val Loss: 0.00078743\n",
      "Epoch 22/100, Train Loss: 0.00069244, Val Loss: 0.00075122\n",
      "Epoch 23/100, Train Loss: 0.00069015, Val Loss: 0.00073398\n",
      "Epoch 24/100, Train Loss: 0.00067328, Val Loss: 0.00068120\n",
      "Best model for fold 3 with train loss: 0.00067328 and val loss: 0.00068120\n",
      "Epoch 25/100, Train Loss: 0.00065287, Val Loss: 0.00068131\n",
      "Epoch 26/100, Train Loss: 0.00064490, Val Loss: 0.00067751\n",
      "Best model for fold 3 with train loss: 0.00064490 and val loss: 0.00067751\n",
      "Epoch 27/100, Train Loss: 0.00063910, Val Loss: 0.00069036\n",
      "Epoch 28/100, Train Loss: 0.00062885, Val Loss: 0.00064502\n",
      "Best model for fold 3 with train loss: 0.00062885 and val loss: 0.00064502\n",
      "Epoch 29/100, Train Loss: 0.00062485, Val Loss: 0.00065169\n",
      "Epoch 30/100, Train Loss: 0.00061996, Val Loss: 0.00064513\n",
      "Epoch 31/100, Train Loss: 0.00062308, Val Loss: 0.00064957\n",
      "Epoch 32/100, Train Loss: 0.00061616, Val Loss: 0.00064000\n",
      "Best model for fold 3 with train loss: 0.00061616 and val loss: 0.00064000\n",
      "Epoch 33/100, Train Loss: 0.00060651, Val Loss: 0.00062281\n",
      "Best model for fold 3 with train loss: 0.00060651 and val loss: 0.00062281\n",
      "Epoch 34/100, Train Loss: 0.00060263, Val Loss: 0.00062071\n",
      "Best model for fold 3 with train loss: 0.00060263 and val loss: 0.00062071\n",
      "Epoch 35/100, Train Loss: 0.00060105, Val Loss: 0.00061975\n",
      "Best model for fold 3 with train loss: 0.00060105 and val loss: 0.00061975\n",
      "Epoch 36/100, Train Loss: 0.00059883, Val Loss: 0.00061828\n",
      "Best model for fold 3 with train loss: 0.00059883 and val loss: 0.00061828\n",
      "Epoch 37/100, Train Loss: 0.00059643, Val Loss: 0.00059580\n",
      "Best model for fold 3 with train loss: 0.00059643 and val loss: 0.00059580\n",
      "Epoch 38/100, Train Loss: 0.00057295, Val Loss: 0.00059581\n",
      "Epoch 39/100, Train Loss: 0.00055978, Val Loss: 0.00058114\n",
      "Best model for fold 3 with train loss: 0.00055978 and val loss: 0.00058114\n",
      "Epoch 40/100, Train Loss: 0.00055601, Val Loss: 0.00060906\n",
      "Epoch 41/100, Train Loss: 0.00055340, Val Loss: 0.00057840\n",
      "Best model for fold 3 with train loss: 0.00055340 and val loss: 0.00057840\n",
      "Epoch 42/100, Train Loss: 0.00054959, Val Loss: 0.00057378\n",
      "Best model for fold 3 with train loss: 0.00054959 and val loss: 0.00057378\n",
      "Epoch 43/100, Train Loss: 0.00055195, Val Loss: 0.00056397\n",
      "Best model for fold 3 with train loss: 0.00055195 and val loss: 0.00056397\n",
      "Epoch 44/100, Train Loss: 0.00054884, Val Loss: 0.00058388\n",
      "Epoch 45/100, Train Loss: 0.00054777, Val Loss: 0.00058845\n",
      "Epoch 46/100, Train Loss: 0.00052069, Val Loss: 0.00052986\n",
      "Best model for fold 3 with train loss: 0.00052069 and val loss: 0.00052986\n",
      "Epoch 47/100, Train Loss: 0.00050344, Val Loss: 0.00053520\n",
      "Epoch 48/100, Train Loss: 0.00050996, Val Loss: 0.00052709\n",
      "Best model for fold 3 with train loss: 0.00050996 and val loss: 0.00052709\n",
      "Epoch 49/100, Train Loss: 0.00050628, Val Loss: 0.00052551\n",
      "Best model for fold 3 with train loss: 0.00050628 and val loss: 0.00052551\n",
      "Epoch 50/100, Train Loss: 0.00051138, Val Loss: 0.00052184\n",
      "Best model for fold 3 with train loss: 0.00051138 and val loss: 0.00052184\n",
      "Epoch 51/100, Train Loss: 0.00050567, Val Loss: 0.00052564\n",
      "Epoch 52/100, Train Loss: 0.00050464, Val Loss: 0.00054508\n",
      "Epoch 53/100, Train Loss: 0.00049486, Val Loss: 0.00053857\n",
      "Epoch 54/100, Train Loss: 0.00050711, Val Loss: 0.00052642\n",
      "Epoch 55/100, Train Loss: 0.00050651, Val Loss: 0.00055039\n",
      "Early stopping at epoch 55 for fold 3\n",
      "\n",
      "Training Fold 4/5\n",
      "Epoch 1/100, Train Loss: 0.01250237, Val Loss: 0.00336589\n",
      "Best model for fold 4 with train loss: 0.01250237 and val loss: 0.00336589\n",
      "Epoch 2/100, Train Loss: 0.00291187, Val Loss: 0.00252594\n",
      "Best model for fold 4 with train loss: 0.00291187 and val loss: 0.00252594\n",
      "Epoch 3/100, Train Loss: 0.00249490, Val Loss: 0.00228422\n",
      "Best model for fold 4 with train loss: 0.00249490 and val loss: 0.00228422\n",
      "Epoch 4/100, Train Loss: 0.00229263, Val Loss: 0.00220589\n",
      "Best model for fold 4 with train loss: 0.00229263 and val loss: 0.00220589\n",
      "Epoch 5/100, Train Loss: 0.00223229, Val Loss: 0.00212668\n",
      "Best model for fold 4 with train loss: 0.00223229 and val loss: 0.00212668\n",
      "Epoch 6/100, Train Loss: 0.00208172, Val Loss: 0.00194413\n",
      "Best model for fold 4 with train loss: 0.00208172 and val loss: 0.00194413\n",
      "Epoch 7/100, Train Loss: 0.00195972, Val Loss: 0.00184386\n",
      "Best model for fold 4 with train loss: 0.00195972 and val loss: 0.00184386\n",
      "Epoch 8/100, Train Loss: 0.00186864, Val Loss: 0.00177983\n",
      "Best model for fold 4 with train loss: 0.00186864 and val loss: 0.00177983\n",
      "Epoch 9/100, Train Loss: 0.00180485, Val Loss: 0.00175493\n",
      "Best model for fold 4 with train loss: 0.00180485 and val loss: 0.00175493\n",
      "Epoch 10/100, Train Loss: 0.00175764, Val Loss: 0.00169123\n",
      "Best model for fold 4 with train loss: 0.00175764 and val loss: 0.00169123\n",
      "Epoch 11/100, Train Loss: 0.00169137, Val Loss: 0.00161500\n",
      "Best model for fold 4 with train loss: 0.00169137 and val loss: 0.00161500\n",
      "Epoch 12/100, Train Loss: 0.00164130, Val Loss: 0.00154237\n",
      "Best model for fold 4 with train loss: 0.00164130 and val loss: 0.00154237\n",
      "Epoch 13/100, Train Loss: 0.00157615, Val Loss: 0.00151458\n",
      "Best model for fold 4 with train loss: 0.00157615 and val loss: 0.00151458\n",
      "Epoch 14/100, Train Loss: 0.00154002, Val Loss: 0.00141919\n",
      "Best model for fold 4 with train loss: 0.00154002 and val loss: 0.00141919\n",
      "Epoch 15/100, Train Loss: 0.00143804, Val Loss: 0.00136015\n",
      "Best model for fold 4 with train loss: 0.00143804 and val loss: 0.00136015\n",
      "Epoch 16/100, Train Loss: 0.00139221, Val Loss: 0.00135645\n",
      "Best model for fold 4 with train loss: 0.00139221 and val loss: 0.00135645\n",
      "Epoch 17/100, Train Loss: 0.00137061, Val Loss: 0.00132626\n",
      "Best model for fold 4 with train loss: 0.00137061 and val loss: 0.00132626\n",
      "Epoch 18/100, Train Loss: 0.00136610, Val Loss: 0.00132455\n",
      "Best model for fold 4 with train loss: 0.00136610 and val loss: 0.00132455\n",
      "Epoch 19/100, Train Loss: 0.00130491, Val Loss: 0.00121207\n",
      "Best model for fold 4 with train loss: 0.00130491 and val loss: 0.00121207\n",
      "Epoch 20/100, Train Loss: 0.00121433, Val Loss: 0.00118536\n",
      "Best model for fold 4 with train loss: 0.00121433 and val loss: 0.00118536\n",
      "Epoch 21/100, Train Loss: 0.00119596, Val Loss: 0.00116919\n",
      "Best model for fold 4 with train loss: 0.00119596 and val loss: 0.00116919\n",
      "Epoch 22/100, Train Loss: 0.00118540, Val Loss: 0.00116119\n",
      "Best model for fold 4 with train loss: 0.00118540 and val loss: 0.00116119\n",
      "Epoch 23/100, Train Loss: 0.00117267, Val Loss: 0.00116184\n",
      "Epoch 24/100, Train Loss: 0.00117132, Val Loss: 0.00124576\n",
      "Epoch 25/100, Train Loss: 0.00117165, Val Loss: 0.00113935\n",
      "Best model for fold 4 with train loss: 0.00117165 and val loss: 0.00113935\n",
      "Epoch 26/100, Train Loss: 0.00116097, Val Loss: 0.00115009\n",
      "Epoch 27/100, Train Loss: 0.00115897, Val Loss: 0.00116159\n",
      "Epoch 28/100, Train Loss: 0.00114991, Val Loss: 0.00114432\n",
      "Epoch 29/100, Train Loss: 0.00114972, Val Loss: 0.00116520\n",
      "Epoch 30/100, Train Loss: 0.00114431, Val Loss: 0.00114947\n",
      "Early stopping at epoch 30 for fold 4\n",
      "\n",
      "Training Fold 5/5\n",
      "Epoch 1/100, Train Loss: 0.01348911, Val Loss: 0.00522928\n",
      "Best model for fold 5 with train loss: 0.01348911 and val loss: 0.00522928\n",
      "Epoch 2/100, Train Loss: 0.00474966, Val Loss: 0.00437042\n",
      "Best model for fold 5 with train loss: 0.00474966 and val loss: 0.00437042\n",
      "Epoch 3/100, Train Loss: 0.00433658, Val Loss: 0.00434361\n",
      "Best model for fold 5 with train loss: 0.00433658 and val loss: 0.00434361\n",
      "Epoch 4/100, Train Loss: 0.00421327, Val Loss: 0.00369088\n",
      "Best model for fold 5 with train loss: 0.00421327 and val loss: 0.00369088\n",
      "Epoch 5/100, Train Loss: 0.00299630, Val Loss: 0.00264074\n",
      "Best model for fold 5 with train loss: 0.00299630 and val loss: 0.00264074\n",
      "Epoch 6/100, Train Loss: 0.00251542, Val Loss: 0.00248010\n",
      "Best model for fold 5 with train loss: 0.00251542 and val loss: 0.00248010\n",
      "Epoch 7/100, Train Loss: 0.00229229, Val Loss: 0.00200348\n",
      "Best model for fold 5 with train loss: 0.00229229 and val loss: 0.00200348\n",
      "Epoch 8/100, Train Loss: 0.00167007, Val Loss: 0.00159761\n",
      "Best model for fold 5 with train loss: 0.00167007 and val loss: 0.00159761\n",
      "Epoch 9/100, Train Loss: 0.00143264, Val Loss: 0.00134814\n",
      "Best model for fold 5 with train loss: 0.00143264 and val loss: 0.00134814\n",
      "Epoch 10/100, Train Loss: 0.00126616, Val Loss: 0.00120886\n",
      "Best model for fold 5 with train loss: 0.00126616 and val loss: 0.00120886\n",
      "Epoch 11/100, Train Loss: 0.00105141, Val Loss: 0.00097971\n",
      "Best model for fold 5 with train loss: 0.00105141 and val loss: 0.00097971\n",
      "Epoch 12/100, Train Loss: 0.00096665, Val Loss: 0.00096169\n",
      "Best model for fold 5 with train loss: 0.00096665 and val loss: 0.00096169\n",
      "Epoch 13/100, Train Loss: 0.00094501, Val Loss: 0.00094271\n",
      "Best model for fold 5 with train loss: 0.00094501 and val loss: 0.00094271\n",
      "Epoch 14/100, Train Loss: 0.00092999, Val Loss: 0.00094829\n",
      "Epoch 15/100, Train Loss: 0.00090377, Val Loss: 0.00085693\n",
      "Best model for fold 5 with train loss: 0.00090377 and val loss: 0.00085693\n",
      "Epoch 16/100, Train Loss: 0.00082637, Val Loss: 0.00084029\n",
      "Best model for fold 5 with train loss: 0.00082637 and val loss: 0.00084029\n",
      "Epoch 17/100, Train Loss: 0.00078358, Val Loss: 0.00076351\n",
      "Best model for fold 5 with train loss: 0.00078358 and val loss: 0.00076351\n",
      "Epoch 18/100, Train Loss: 0.00073418, Val Loss: 0.00073147\n",
      "Best model for fold 5 with train loss: 0.00073418 and val loss: 0.00073147\n",
      "Epoch 19/100, Train Loss: 0.00071838, Val Loss: 0.00075846\n",
      "Epoch 20/100, Train Loss: 0.00070685, Val Loss: 0.00072160\n",
      "Best model for fold 5 with train loss: 0.00070685 and val loss: 0.00072160\n",
      "Epoch 21/100, Train Loss: 0.00069965, Val Loss: 0.00069694\n",
      "Best model for fold 5 with train loss: 0.00069965 and val loss: 0.00069694\n",
      "Epoch 22/100, Train Loss: 0.00068886, Val Loss: 0.00069875\n",
      "Epoch 23/100, Train Loss: 0.00066058, Val Loss: 0.00066089\n",
      "Best model for fold 5 with train loss: 0.00066058 and val loss: 0.00066089\n",
      "Epoch 24/100, Train Loss: 0.00063690, Val Loss: 0.00063796\n",
      "Best model for fold 5 with train loss: 0.00063690 and val loss: 0.00063796\n",
      "Epoch 25/100, Train Loss: 0.00062468, Val Loss: 0.00065421\n",
      "Epoch 26/100, Train Loss: 0.00062325, Val Loss: 0.00063843\n",
      "Epoch 27/100, Train Loss: 0.00062328, Val Loss: 0.00063716\n",
      "Best model for fold 5 with train loss: 0.00062328 and val loss: 0.00063716\n",
      "Epoch 28/100, Train Loss: 0.00061080, Val Loss: 0.00062605\n",
      "Best model for fold 5 with train loss: 0.00061080 and val loss: 0.00062605\n",
      "Epoch 29/100, Train Loss: 0.00061039, Val Loss: 0.00062754\n",
      "Epoch 30/100, Train Loss: 0.00059364, Val Loss: 0.00060155\n",
      "Best model for fold 5 with train loss: 0.00059364 and val loss: 0.00060155\n",
      "Epoch 31/100, Train Loss: 0.00059063, Val Loss: 0.00061093\n",
      "Epoch 32/100, Train Loss: 0.00059031, Val Loss: 0.00063618\n",
      "Epoch 33/100, Train Loss: 0.00058734, Val Loss: 0.00059689\n",
      "Best model for fold 5 with train loss: 0.00058734 and val loss: 0.00059689\n",
      "Epoch 34/100, Train Loss: 0.00058349, Val Loss: 0.00058969\n",
      "Best model for fold 5 with train loss: 0.00058349 and val loss: 0.00058969\n",
      "Epoch 35/100, Train Loss: 0.00057444, Val Loss: 0.00058701\n",
      "Best model for fold 5 with train loss: 0.00057444 and val loss: 0.00058701\n",
      "Epoch 36/100, Train Loss: 0.00057831, Val Loss: 0.00058843\n",
      "Epoch 37/100, Train Loss: 0.00056602, Val Loss: 0.00060399\n",
      "Epoch 38/100, Train Loss: 0.00055942, Val Loss: 0.00059097\n",
      "Epoch 39/100, Train Loss: 0.00056202, Val Loss: 0.00056994\n",
      "Best model for fold 5 with train loss: 0.00056202 and val loss: 0.00056994\n",
      "Epoch 40/100, Train Loss: 0.00054833, Val Loss: 0.00054260\n",
      "Best model for fold 5 with train loss: 0.00054833 and val loss: 0.00054260\n",
      "Epoch 41/100, Train Loss: 0.00053529, Val Loss: 0.00056157\n",
      "Epoch 42/100, Train Loss: 0.00052669, Val Loss: 0.00055487\n",
      "Epoch 43/100, Train Loss: 0.00053128, Val Loss: 0.00054148\n",
      "Best model for fold 5 with train loss: 0.00053128 and val loss: 0.00054148\n",
      "Epoch 44/100, Train Loss: 0.00052268, Val Loss: 0.00058573\n",
      "Epoch 45/100, Train Loss: 0.00052854, Val Loss: 0.00052871\n",
      "Best model for fold 5 with train loss: 0.00052854 and val loss: 0.00052871\n",
      "Epoch 46/100, Train Loss: 0.00051427, Val Loss: 0.00053721\n",
      "Epoch 47/100, Train Loss: 0.00051011, Val Loss: 0.00051719\n",
      "Best model for fold 5 with train loss: 0.00051011 and val loss: 0.00051719\n",
      "Epoch 48/100, Train Loss: 0.00051218, Val Loss: 0.00052254\n",
      "Epoch 49/100, Train Loss: 0.00050718, Val Loss: 0.00053085\n",
      "Epoch 50/100, Train Loss: 0.00050232, Val Loss: 0.00051695\n",
      "Best model for fold 5 with train loss: 0.00050232 and val loss: 0.00051695\n",
      "Epoch 51/100, Train Loss: 0.00050409, Val Loss: 0.00050740\n",
      "Best model for fold 5 with train loss: 0.00050409 and val loss: 0.00050740\n",
      "Epoch 52/100, Train Loss: 0.00048361, Val Loss: 0.00046478\n",
      "Best model for fold 5 with train loss: 0.00048361 and val loss: 0.00046478\n",
      "Epoch 53/100, Train Loss: 0.00041944, Val Loss: 0.00046243\n",
      "Best model for fold 5 with train loss: 0.00041944 and val loss: 0.00046243\n",
      "Epoch 54/100, Train Loss: 0.00042074, Val Loss: 0.00044562\n",
      "Best model for fold 5 with train loss: 0.00042074 and val loss: 0.00044562\n",
      "Epoch 55/100, Train Loss: 0.00041713, Val Loss: 0.00046419\n",
      "Epoch 56/100, Train Loss: 0.00042602, Val Loss: 0.00044673\n",
      "Epoch 57/100, Train Loss: 0.00041329, Val Loss: 0.00046408\n",
      "Epoch 58/100, Train Loss: 0.00041354, Val Loss: 0.00043889\n",
      "Best model for fold 5 with train loss: 0.00041354 and val loss: 0.00043889\n",
      "Epoch 59/100, Train Loss: 0.00042010, Val Loss: 0.00044256\n",
      "Epoch 60/100, Train Loss: 0.00040897, Val Loss: 0.00043174\n",
      "Best model for fold 5 with train loss: 0.00040897 and val loss: 0.00043174\n",
      "Epoch 61/100, Train Loss: 0.00041294, Val Loss: 0.00043382\n",
      "Epoch 62/100, Train Loss: 0.00041028, Val Loss: 0.00044943\n",
      "Epoch 63/100, Train Loss: 0.00040676, Val Loss: 0.00044586\n",
      "Epoch 64/100, Train Loss: 0.00041302, Val Loss: 0.00043361\n",
      "Epoch 65/100, Train Loss: 0.00040454, Val Loss: 0.00043782\n",
      "Early stopping at epoch 65 for fold 5\n",
      "\n",
      "K-Fold Cross-Validation Results:\n",
      "Fold 1: Best Validation Loss = 0.00027885, Train Loss = 0.00026308\n",
      "Fold 2: Best Validation Loss = 0.00023471, Train Loss = 0.00021787\n",
      "Fold 3: Best Validation Loss = 0.00052184, Train Loss = 0.00050651\n",
      "Fold 4: Best Validation Loss = 0.00113935, Train Loss = 0.00114431\n",
      "Fold 5: Best Validation Loss = 0.00043174, Train Loss = 0.00040454\n"
     ]
    }
   ],
   "source": [
    "''' K-fold Cross-Validation '''\n",
    "\n",
    "# Initialize KFold with 5 folds\n",
    "k = 5\n",
    "kf = KFold(n_splits=k, shuffle=True, random_state=42)\n",
    "\n",
    "# Training hyperparameters\n",
    "batch_size = 32\n",
    "num_epochs = 100\n",
    "patience = 5    # Number of events to wait if no improvement\n",
    "epochs_no_improvement = [] # Store ordinal number of epochs, where the early stopping was triggered\n",
    "learning_rate = 0.001\n",
    "\n",
    "# Lists to store validation losses and train losses for each fold\n",
    "val_losses = []\n",
    "train_losses = []\n",
    "\n",
    "# Convert the normal_train_encoded to tensor\n",
    "normal_train_encoded_tensor = torch.tensor(normal_train_encoded.values, dtype=torch.float32)\n",
    "\n",
    "# K-fold cross-validation loop\n",
    "for fold, (train_idx, val_idx) in enumerate(kf.split(normal_train_encoded_tensor)):\n",
    "    print(f\"\\nTraining Fold {fold + 1}/{k}\")\n",
    "\n",
    "    # Create training and validation subsets\n",
    "    train_subset = normal_train_encoded_tensor[train_idx]\n",
    "    val_subset = normal_train_encoded_tensor[val_idx]\n",
    "\n",
    "    # Create DataLoaders\n",
    "    # The input and target are the same for autoencoders, so we use the same dataset for both\n",
    "    train_dataset = TensorDataset(train_subset, train_subset)  \n",
    "    val_dataset = TensorDataset(val_subset, val_subset)\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "    # Initialize model, loss, and optimizer\n",
    "    model = AutoEncoder()\n",
    "    criterion = nn.MSELoss()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "    # Early stopping variables\n",
    "    best_val_loss = float('inf')\n",
    "    patience_counter = 0\n",
    "\n",
    "    # Training loop\n",
    "    for epoch in range(num_epochs):\n",
    "        # Training phase\n",
    "        model.train()\n",
    "        train_loss = 0.0\n",
    "        for data in train_loader:\n",
    "            inputs, targets = data\n",
    "\n",
    "            # Clear gradients for the next batch\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # Forward pass\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, targets)\n",
    "\n",
    "            # Backward pass\n",
    "            loss.backward()\n",
    "\n",
    "            # Update parameters\n",
    "            optimizer.step()\n",
    "            \n",
    "            # Accumulate training loss\n",
    "            train_loss += loss.item() * inputs.size(0)\n",
    "    \n",
    "        # Average training loss\n",
    "        train_loss /= len(train_loader.dataset)\n",
    "\n",
    "        # Validation phase\n",
    "        model.eval()    # Set model to evaluation mode\n",
    "        val_loss = 0.0\n",
    "        with torch.no_grad():   # Disable gradient calculation\n",
    "            for data in val_loader:\n",
    "                inputs, targets = data\n",
    "                outputs = model(inputs)\n",
    "                loss = criterion(outputs, targets)\n",
    "                val_loss += loss.item() * inputs.size(0)\n",
    "\n",
    "        # Average validation loss\n",
    "        val_loss /= len(val_loader.dataset)\n",
    "\n",
    "        print(f'Epoch {epoch + 1}/{num_epochs}, Train Loss: {train_loss:.8f}, Val Loss: {val_loss:.8f}')\n",
    "\n",
    "        # Early stopping\n",
    "        if val_loss < best_val_loss:\n",
    "            best_val_loss = val_loss\n",
    "            patience_counter = 0\n",
    "            print(f\"Best model for fold {fold + 1} with train loss: {train_loss:.8f} and val loss: {best_val_loss:.8f}\")\n",
    "        else:\n",
    "            patience_counter += 1\n",
    "            if patience_counter >= patience:\n",
    "                print(f\"Early stopping at epoch {epoch + 1} for fold {fold + 1}\")\n",
    "                epochs_no_improvement.append(epoch + 1)\n",
    "                break\n",
    "    \n",
    "    # Store the best validation loss and the corresponded train loss for this fold\n",
    "    val_losses.append(best_val_loss)\n",
    "    train_losses.append(train_loss)\n",
    "     \n",
    "# Print results after training\n",
    "print(\"\\nK-Fold Cross-Validation Results:\")\n",
    "for fold in range(k):\n",
    "    print(f\"Fold {fold + 1}: Best Validation Loss = {val_losses[fold]:.8f}, Train Loss = {train_losses[fold]:.8f}\")\n",
    "      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "a1c2fc11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "55.0\n",
      "[60, 66, 55, 30, 65]\n"
     ]
    }
   ],
   "source": [
    "num_epochs = np.round(np.mean(np.array(epochs_no_improvement))) if len(epochs_no_improvement) > 0 else num_epochs\n",
    "\n",
    "print(num_epochs)\n",
    "print(epochs_no_improvement)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "d31abd86",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retraining model for 55 epochs on the entire training dataset.\n",
      "Epoch 1/55, Train Loss: 0.01076670\n",
      "Epoch 2/55, Train Loss: 0.00233232\n",
      "Epoch 3/55, Train Loss: 0.00194208\n",
      "Epoch 4/55, Train Loss: 0.00176649\n",
      "Epoch 5/55, Train Loss: 0.00166646\n",
      "Epoch 6/55, Train Loss: 0.00160526\n",
      "Epoch 7/55, Train Loss: 0.00142653\n",
      "Epoch 8/55, Train Loss: 0.00130320\n",
      "Epoch 9/55, Train Loss: 0.00119907\n",
      "Epoch 10/55, Train Loss: 0.00114234\n",
      "Epoch 11/55, Train Loss: 0.00104453\n",
      "Epoch 12/55, Train Loss: 0.00101859\n",
      "Epoch 13/55, Train Loss: 0.00100148\n",
      "Epoch 14/55, Train Loss: 0.00088805\n",
      "Epoch 15/55, Train Loss: 0.00083048\n",
      "Epoch 16/55, Train Loss: 0.00080895\n",
      "Epoch 17/55, Train Loss: 0.00078999\n",
      "Epoch 18/55, Train Loss: 0.00077395\n",
      "Epoch 19/55, Train Loss: 0.00076433\n",
      "Epoch 20/55, Train Loss: 0.00074261\n",
      "Epoch 21/55, Train Loss: 0.00072200\n",
      "Epoch 22/55, Train Loss: 0.00069242\n",
      "Epoch 23/55, Train Loss: 0.00068000\n",
      "Epoch 24/55, Train Loss: 0.00065824\n",
      "Epoch 25/55, Train Loss: 0.00064971\n",
      "Epoch 26/55, Train Loss: 0.00063815\n",
      "Epoch 27/55, Train Loss: 0.00063230\n",
      "Epoch 28/55, Train Loss: 0.00062856\n",
      "Epoch 29/55, Train Loss: 0.00062427\n",
      "Epoch 30/55, Train Loss: 0.00062256\n",
      "Epoch 31/55, Train Loss: 0.00061824\n",
      "Epoch 32/55, Train Loss: 0.00061829\n",
      "Epoch 33/55, Train Loss: 0.00061171\n",
      "Epoch 34/55, Train Loss: 0.00060840\n",
      "Epoch 35/55, Train Loss: 0.00054385\n",
      "Epoch 36/55, Train Loss: 0.00051611\n",
      "Epoch 37/55, Train Loss: 0.00051172\n",
      "Epoch 38/55, Train Loss: 0.00050582\n",
      "Epoch 39/55, Train Loss: 0.00050134\n",
      "Epoch 40/55, Train Loss: 0.00049861\n",
      "Epoch 41/55, Train Loss: 0.00049744\n",
      "Epoch 42/55, Train Loss: 0.00049629\n",
      "Epoch 43/55, Train Loss: 0.00049342\n",
      "Epoch 44/55, Train Loss: 0.00049155\n",
      "Epoch 45/55, Train Loss: 0.00048410\n",
      "Epoch 46/55, Train Loss: 0.00048725\n",
      "Epoch 47/55, Train Loss: 0.00047331\n",
      "Epoch 48/55, Train Loss: 0.00046811\n",
      "Epoch 49/55, Train Loss: 0.00046037\n",
      "Epoch 50/55, Train Loss: 0.00044625\n",
      "Epoch 51/55, Train Loss: 0.00044166\n",
      "Epoch 52/55, Train Loss: 0.00044351\n",
      "Epoch 53/55, Train Loss: 0.00043995\n",
      "Epoch 54/55, Train Loss: 0.00044140\n",
      "Epoch 55/55, Train Loss: 0.00043316\n",
      "Model saved to output/final_model.pth\n"
     ]
    }
   ],
   "source": [
    "''' Retrain the model on the entire training dataset (only datas flagged as normal) '''\n",
    "\n",
    "# Create a DataLoader for the entire normal training dataset\n",
    "full_normal_train_dataset = TensorDataset(normal_train_encoded_tensor, normal_train_encoded_tensor)\n",
    "full_normal_train_loader = DataLoader(full_normal_train_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "# Path to save the model\n",
    "model_path = 'output/final_model.pth'\n",
    "\n",
    "# Initialize model, loss, and optimizer\n",
    "model = AutoEncoder()\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "# Number of epochs for retraining\n",
    "num_epochs = np.round(np.mean(np.array(epochs_no_improvement))) if len(epochs_no_improvement) > 0 else num_epochs\n",
    "num_epochs = int(num_epochs)\n",
    "print(f\"Retraining model for {num_epochs} epochs on the entire training dataset.\")\n",
    "\n",
    "# Training loop for the entire dataset\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    train_loss = 0.0\n",
    "    for data in full_normal_train_loader:\n",
    "        inputs, targets = data\n",
    "\n",
    "        # Clear gradients for the next batch\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Forward pass\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, targets)\n",
    "\n",
    "        # Backward pass\n",
    "        loss.backward()\n",
    "\n",
    "        # Update parameters\n",
    "        optimizer.step()\n",
    "        \n",
    "        # Accumulate training loss\n",
    "        train_loss += loss.item() * inputs.size(0)\n",
    "\n",
    "    # Average training loss\n",
    "    train_loss /= len(full_normal_train_loader.dataset)\n",
    "\n",
    "    print(f'Epoch {epoch + 1}/{num_epochs}, Train Loss: {train_loss:.8f}')\n",
    "\n",
    "# Save the model for inference\n",
    "torch.save(model.state_dict(), model_path)\n",
    "print(f\"Model saved to {model_path}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nsl_kdd",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
